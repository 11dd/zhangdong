<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[zhangdong]]></title>
  <link href="www.freefook.com/atom.xml" rel="self"/>
  <link href="www.freefook.com/"/>
  <updated>2017-12-22T14:23:56+08:00</updated>
  <id>www.freefook.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im">MWeb</generator>

  
  <entry>
    <title type="html"><![CDATA[联系方式]]></title>
    <link href="www.freefook.com/15139235853705.html"/>
    <updated>2017-12-22T14:19:45+08:00</updated>
    <id>www.freefook.com/15139235853705.html</id>
    <content type="html"><![CDATA[
<p>邮箱：<a href="mailto:jsjzdd_2014@126.com">jsjzdd_2014@126.com</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS ARKit 看我就受够了]]></title>
    <link href="www.freefook.com/15139220095625.html"/>
    <updated>2017-12-22T13:53:29+08:00</updated>
    <id>www.freefook.com/15139220095625.html</id>
    <content type="html"><![CDATA[
<p>因为有项目需求ARKit，查询后反馈的文档<br/>
现发布出来，还没注明转载出自哪里，见谅，找到地址时补齐；</p>

<p><a href="https://developer.apple.com/documentation/arkit">https://developer.apple.com/documentation/arkit</a><br/>
<img src="http://upload-images.jianshu.io/upload_images/670820-3bdc5004b7ecbc6c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""/>截图</p>

<h3 id="toc_0">AR增强现实技术</h3>

<p>在即将发布的iOS11系统上，ARKit正式成为iOS系统框架，让开发者能够使用OC或swift语言开发AR类型的APP。<br/>
ARKit的大部分计算都是在CPU上处理的，在A8处理器上的性能损耗在15%~ 25%,<br/>
在A9处理器上的性能损耗在10% ~ 15%。为了更好的体验，所以苹果仅支持 A9 及以上处理器<br/>
<img src="http://upload-images.jianshu.io/upload_images/670820-2eaafcbc013d5c9a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""/>AR支持系列</p>

<h4 id="toc_1">ARKit 实现测量尺功能：</h4>

<p>实现该功能原理:收集相机的视觉信息，以及手机中传感器，包括陀螺仪、罗盘和加速度计来计算并确定设备的位置。<br/>
当然，这都是基于ARKit开发的，不想深入，想深入，深入，入...</p>

<blockquote>
<p>•多媒体捕捉现实图像:如摄像头<br/>
•三维建模:3D立体模型<br/>
•传感器追踪:主要追踪现实世界动态物体的六轴变化，这六轴分别是X、Y、Z轴位移及旋转。其中位移三轴决定物体的方位和大小，旋转三轴决定物体显示的区域。<br/>
•坐标识别及转换:3D模型显示在现实图像中不是单纯的坐标点，而是一个三维的矩阵坐标</p>
</blockquote>

<h4 id="toc_2">注意:</h4>

<ol>
<li><p>如果手机中的场景越丰富，那么测量的结果也就越精确。如果想要测量一面白墙的长度，暂时还不是很准确。AR应用是通过“特征点”进行识别的,也因为是三维矩阵坐标，要求测量时必须很稳的在同一个 Z 轴高度上测量平面的长度;</p></li>
<li><p>不要期望 AR检测的平面会完全贴合表面，虽然检测到了平面但角度可能不完全正确，所以如果开发的AR app需要获得非常精确的几何体来提供更好的效果，可能会出现问题</p></li>
<li><p>边缘检测不是特别好，实际的平面范围有时会太大或太小，所以不要尝试做需要准确边缘的 ARapp</p></li>
</ol>

<h4 id="toc_3">ARKit还存在一些问题:</h4>

<blockquote>
<p>ARKit是基于惯性-视觉来做空间定位的，这项技术会将iOS设备的动作感测硬件信息，加上对可见场景的计算机视觉分析功能，然后与设备的摄像头相结合，需要平稳缓慢的移动+转向手机，才能构建更加准确的世界，这对用户来说是一种考验，需要积极提示。</p>

<p>一旦刚开始检测平面失败，出现时间久，飘逸的现象，后期很难再正确检测，要强制重启。</p>

<p>AVFoudation与ARSession之间的切换会有轻微的卡顿，切换后ARSession就停止摄像头采集了，但3D渲染会继续，只是丧失了空间定位与检测识别的能力.</p>

<p>不支持前置摄像头。ARKit并不是一个用于前置摄像头环境的技术，因为空间有限，能提供的信息也非常有限。100米左右是ARKit在保持较好用户体验的最大测量距离。</p>

<p>ARKit没有计划支持连接两个不同ARKit世界。</p>
</blockquote>

<h4 id="toc_4">要建立高品质的 AR 体验，那么请注意下述这些注意事项和提示:</h4>

<blockquote>
<p>全局追踪是一项不精确的科学 (inexact science)。<br/>
尽管在这个过程当中，经常会产生可观的准确度，从而让AR 的体验更加真实。然而，它严重依赖于设备物理环境的相关细节，而这些细节并不总是一致，有些时候也难以实时测量，这也就导致这些物理细节往往都会存在某种程度的错误。</p>

<p>基于可见的照明条件来设计AR场景。<br/>
全局追踪涉及到了图像分析的相关内容，因此就需要我们提供清晰的图像。如果摄像头没有办法看到相关的物理细节，比如说摄像头拍到的是一面空空如也的墙壁，或者场景的光线实在太暗的话，那么全局追踪的质量就会大大降低。</p>

<p>根据追踪质量的相关信息来给用户进行反馈提示。<br/>
全局追踪会将图像分析与设备的动作模式关联起来。如果设备正在移动的话，那么ARKit 就可以更好地对场景进行建模，这样即便设备只是略微晃动，也不会影响追踪质量。但是一旦用户的动作过多、过快或者晃动过于激烈，就会导致图像变得模糊，或者导致视频帧中要追踪的特征之间的距离过大，从而致使追踪质量的降低。ARCamera类能够提供追踪状态，此外还能提供导致该状态出现的相关原因，您可以在 UI 上展示这些信息，告诉用户如何解决追踪质量低这个问题。</p>

<p>给水平面检测预留点时间来生成清晰的结果，一旦您获得所需的结果后，就禁用水平面检测。一开始对水平面进行检测的时候，所检测到的水平面位置和范围很可能不准确。不过随着时间的推移，只要水平面仍然保持在场景当中，<br/>
那么 ARKit 就能够较为精确地估计水平面的位置和范围。当场景中有一个比较大的平坦表面的话，就算您已经使用过这个水平面来放置内容，那么 ARKit 可能还会继续对水平面的锚点位置、范围和变换点进行修正 。</p>
</blockquote>

<p>综上所述:ARKit 实现测量尺功能，对物理环境要求较高，<br/>
第一，环境光检测，清晰的获取摄像头的帧图像;<br/>
第二，平面检测，准确的获取水平面，如果精确测量，需要边缘化检测准确;<br/>
第三，运动追踪稳定准确等外部因素，对环境和用户操作要求较高;</p>

<h4 id="toc_5">后记补充：</h4>

<p>ARKit是有环境光估计的，这个功能会通过摄像头捕捉并计算捕捉到的场景中的光的总量，来给虚拟物体施加正确的光照条件，渲染效果更加真实。环境光的模拟对于AR出来的画面的真实感，还是有非常大的影响的。</p>

<h5 id="toc_6">在此说一下ARKit没有提供图像识别方面的功能，所以平时可能看到身边有的AR场景是可以识别特定的图像做其他操作类型的App，用ARKit是不能实现的；</h5>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS 权限问题]]></title>
    <link href="www.freefook.com/15139219822825.html"/>
    <updated>2017-12-22T13:53:02+08:00</updated>
    <id>www.freefook.com/15139219822825.html</id>
    <content type="html"><![CDATA[
<pre><code>定位要写清楚用途，例如（为您导航, 到您想去的健身门店。）否则会遭拒绝的在水果商店
定位权限：Privacy - Location When In Use Usage Description         
定位权限: Privacy - Location Always Usage Description                
相机权限：Privacy - Camera Usage Description    是否允许此App使用你的相机？
相册权限： Privacy - Photo Library Usage Description   是否允许此App访问你的媒体资料库？
通讯录权限： Privacy - Contacts Usage Description                           
麦克风权限： Privacy - Microphone Usage Description                      
蓝牙权限： Privacy - Bluetooth Peripheral Usage Description           
日历权限：Privacy - Calendars Usage Description                         
语音转文字权限：Privacy - Speech Recognition Usage Description            
健康数据分享:  Privacy - Health Share Usage Description  
健康数据更新: Privacy - Health Update Usage Description 
运动传感器: Privacy - Motion Usage Description  
音乐:  Privacy - Music Usage Description  
播放音乐或者视频:  Privacy - Media Library Usage Description  
Siri:    Privacy - Siri Usage Description  
智能家具:  Privacy - HomeKit Usage Description  
电视提供商:   Privacy - TV Provider Usage Description  
视频订阅:  Privacy - Video Subscriber Account Usage Description 
备忘录: Privacy - Reminders Usage Description

</code></pre>

<pre><code>网络请求的ATS如下：
App Transport Security Settings  （Type:Dictionary）
在添加子项如下：
Allow Arbitrary Loads            （Type:Boolean）设置为YES
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AES加密打开方式...]]></title>
    <link href="www.freefook.com/15139219514745.html"/>
    <updated>2017-12-22T13:52:31+08:00</updated>
    <id>www.freefook.com/15139219514745.html</id>
    <content type="html"><![CDATA[
<p>很久没写博客,Markdown牵出来遛遛</p>

<p>AES加密时需要统一的几个参数。</p>

<pre><code>密钥长度（Key Size）
加密模式（Cipher Mode）
填充方式（Padding）
初始向量（Initialization Vector）
</code></pre>

<blockquote>
<p>1.本例使用AES-128,</p>

<p>2.AES属于块加密BlockCipher，块加密中有CBC、ECB、CTR、OFB、CFB等几种工作模式。本例使用CBC模式</p>

<p>3.由于块加密只能对特定长度的数据块进行加密，因此CBC、ECB模式需要在最后一数据块加密前进行数据填充。（CFB，OFB和CTR模式由于与key进行加密操作的是上一块加密后的密文，因此不需要对最后一段明文进行填充）<br/>
在iOS SDK中提供了PKCS7Padding</p>
</blockquote>

<p>ECB加密模式（不推荐）：容易被攻击</p>

<blockquote>
<p>1.每次key,明文,密文的长度都必须是64位;<br/><br/>
2.数据块重复排序不需要检测;<br/><br/>
3.相同的明文块(使用相同的密钥)产生相同的密文块,容易遭受字典被攻击<br/><br/>
4.一个错误仅仅会对一个密文块产生影响</p>
</blockquote>

<p>CBC加密方式(推荐):</p>

<blockquote>
<p>1.每次加密的密文长度为64位(8个字节);<br/><br/>
2.当相同的明文使用相同的密钥和初始向量的时候CBC模式总是产生相同的密文;<br/><br/>
3.密文块要依赖以前的操作结果,所以密文块不能进行重新排列;<br/><br/>
4.可以使用不同的初始化向量来避免相同的明文产生相同的密文,一定程度上抵抗字典攻击<br/>
5.一个错误发生后,当前和以后的密文都会被影响;</p>

<p>使用PKCS5Padding/PKCS7Padding填充可以兼容多平台语言之间AES加密解密  </p>

<p>注意: 这里每次产生的密文是相同的，因为设置了初试向量iv为16位个数的“0”。要产生不同的密文就要使用变化的初试向量iv</p>
</blockquote>

<p>ios使用案例  </p>

<p>创建一个类AESCipher继承NSObject</p>

<p>.h文件如下:</p>

<pre><code>#import &lt;Foundation/Foundation.h&gt;
NSString * aesEncryptString(NSString *content, NSString *key);
NSString * aesDecryptString(NSString *content, NSString *key);
NSData * aesEncryptData(NSData *data, NSData *key);
NSData * aesDecryptData(NSData *data, NSData *key);

</code></pre>

<p>.m文件如下:</p>

<pre><code>#import &quot;AESCipher.h&quot;
#import &lt;CommonCrypto/CommonCryptor.h&gt;
//注意:初始向量,默认16个0(]前后端保持统一)
NSString const *kInitVector = @&quot;0000000000000000&quot;;
size_t const kKeySize = kCCKeySizeAES128;
NSData * cipherOperation(NSData *contentData, NSData *keyData, CCOperation operation) {
    NSUInteger dataLength = contentData.length;
    void const *initVectorBytes = [kInitVector dataUsingEncoding:NSUTF8StringEncoding].bytes;
    void const *contentBytes = contentData.bytes;
    void const *keyBytes = keyData.bytes;
    size_t operationSize = dataLength + kCCBlockSizeAES128;
    void *operationBytes = malloc(operationSize);
    size_t actualOutSize = 0;
    CCCryptorStatus cryptStatus = CCCrypt(operation,                                   kCCAlgorithmAES,                                   kCCOptionPKCS7Padding,
 keyBytes,                                      kKeySize,                                     initVectorBytes,                                    contentBytes,                                     dataLength,                                     operationBytes,                                    operationSize,                                   &amp;actualOutSize);
    if (cryptStatus == kCCSuccess) {
        return [NSData dataWithBytesNoCopy:operationBytes length:actualOutSize];
    }
    free(operationBytes);
    return nil;
}
NSString * aesEncryptString(NSString *content, NSString *key) {
    NSData *contentData = [content dataUsingEncoding:NSUTF8StringEncoding];
    NSData *keyData = [key dataUsingEncoding:NSUTF8StringEncoding];
    NSData *encrptedData = aesEncryptData(contentData, keyData);
    return [encrptedData base64EncodedStringWithOptions:NSDataBase64EncodingEndLineWithLineFeed];
}
NSString * aesDecryptString(NSString *content, NSString *key) {
    NSData *contentData = [[NSData alloc] initWithBase64EncodedString:content options:NSDataBase64DecodingIgnoreUnknownCharacters];
    NSData *keyData = [key dataUsingEncoding:NSUTF8StringEncoding];
    NSData *decryptedData = aesDecryptData(contentData, keyData);
    return [[NSString alloc] initWithData:decryptedData encoding:NSUTF8StringEncoding];
}
NSData * aesEncryptData(NSData *contentData, NSData *keyData) {
    NSString *hint = [NSString stringWithFormat:@&quot;The key size of AES-%lu should be %lu bytes!&quot;, kKeySize * 8, kKeySize];
    NSCAssert(keyData.length == kKeySize, hint);
    return cipherOperation(contentData, keyData, kCCEncrypt);
}
NSData * aesDecryptData(NSData *contentData, NSData *keyData) {
    NSString *hint = [NSString stringWithFormat:@&quot;The key size of AES-%lu should be %lu bytes!&quot;, kKeySize * 8, kKeySize];
    NSCAssert(keyData.length == kKeySize, hint);
    return cipherOperation(contentData, keyData, kCCDecrypt);
}
</code></pre>

<p>使用方法如下:</p>

<pre><code>/*
 使用案例:
 第一: 导入头文件
 #import &quot;AESCipher.h&quot;
 测试字符串
 NSString *TestStr = @&quot;abc&quot;;
 设置key
 NSString *key = @&quot;1234567812345678&quot;;
 NSString *cipherText = aesEncryptString(TestStr, key);
 NSLog(@&quot;加密==%@&quot;, cipherText);
 NSString *decryptedText = aesDecryptString(cipherText, key);
 NSLog(@&quot;解密==%@&quot;, decryptedText);
 */
</code></pre>

<p>原文查看:<br/>
 <a href="http://blog.csdn.net/u013749540/article/details/70225594">http://blog.csdn.net/u013749540/article/details/70225594</a><br/>
 <a href="http://www.cnblogs.com/dcb3688/p/4608007.html">http://www.cnblogs.com/dcb3688/p/4608007.html</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[互动直播变身视频会议]]></title>
    <link href="www.freefook.com/15139219144104.html"/>
    <updated>2017-12-22T13:51:54+08:00</updated>
    <id>www.freefook.com/15139219144104.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">视频会议</h2>

<blockquote>
<p>初试水: 需求是13人同屏视频会议,最多进入视频会议房间的人数上线也就是13人;<br/>
也因最大障碍网络问题,设备问题,<br/>
很难支撑稳定的长时间连接这么多路的视频通话而被放弃;</p>

<p>在思考: 用互动直播模式,改进视频会议方案<br/>
为了视频会议的稳定性:减少至视频人员数量(4人),<br/>
现有APP调查: QQ视频同时4人;微信支持9人;<br/>
直播类属于连麦, YY4人 ,直播类有多的是连6人;<br/>
淘宝旗下的产品,钉钉视频会议5人;</p>

<p>方案一:因为视频人员数量只有4人,后台创建会议时应设置有权限视频的人员;<br/>
其余人默认观众模式,只可语音;<br/>
这就抛出了第一个问题?<br/>
谁能视频会议,分配给谁这个权限的问题?<br/>
所以:后台添加开会人员时;分配视频权限;(谁是视频显示,其他人默认语音)<br/>
房间只能是有视频权限的人创建,谁是房主有最高权限,这个人是</p>
</blockquote>

<h1 id="toc_1">一. 网易云互动直播</h1>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-c7961d44fe677e47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午1.30.36.png"/></p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-812f5105d2624c04.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午1.36.55.png"/></p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-2a227a96dae9afb1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午1.32.17.png"/></p>

<h4 id="toc_2">功能概述</h4>

<blockquote>
<p>网易云通信的互动直播功能，支持主播和观众实时连麦互动。<br/>
互动直播由连麦互动和直播两部分组成，其中连麦互动基于音视频通话实现，可以实现1个主播+3个连麦者的音视频通话连麦（基于私有协议实现）。<br/>
主播和连麦者的音视频数据在互动直播高性能服务器合成为一道流后推流到CDN流媒体服务器，普通观众拉流观看即可（RTMP推流协议)</p>
</blockquote>

<h4 id="toc_3">互动直播接入流程</h4>

<blockquote>
<p>1.接入IM账号体系：单独的直播并不需要接入账号体系，但是互动连麦是基于音视频通话做的，音视频通话是基于IM的账号体系的，所以这边需要给主播和连麦者都分配IM账号。由服务端创建IM账号;<br/>
2.客户端接入IM的SDK，登录IM<br/>
3.客户端接入音视频通话SDK，实现主播和连麦者的音视频通话。（互动直播基于音视频多人会议开发，通过将多人会议中用户的音视频数据处理后推送给视频流服务器实现直播和实时连麦。 在功能的提供上，互动直播复用多人音视频接口，增加互动开关、推流地址指定与切换、直播角色指定等扩展设置）<br/>
4.接入直播，服务端创建频道后获取推流地址，在主播端设置该推流地址。<br/>
5.观众使用该推流地址对应的拉流地址观看（支持HLS (m3u8)、RTMP、HTTP-FLV等拉流协议），可接入直播的拉流播放器。</p>
</blockquote>

<h4 id="toc_4">demo简介</h4>

<blockquote>
<p>互动直播Demo在互动连麦的基础上还接入了无人数上限的聊天室，来实现文字互动、点赞、送礼物等多种消息形式。<br/>
1.聊天室的是由服务端创建并管理的。客户端在登录IM成功后根据服务端提供的roomid加入聊天室即可。所以聊天室也是基于IM的账号体系的。<br/>
2.聊天室的消息收发。</p>
</blockquote>

<h4 id="toc_5">demo各功能说明：</h4>

<blockquote>
<p>1.注册，客户端获取注册信息后发给demo服务器，由demo服务器完成。（账号体系）<br/>
2.客户端初始化SDK，登录IM<br/>
3.demo服务器创建直播频道获取推拉流地址。<br/>
4.demo服务器创建聊天室。<br/>
5.主播客户端创建音视频通话房间，从demo服务器获取推流地址后，开启推流开关。<br/>
6.各客户端加入聊天室。<br/>
7.连麦者加入主播创建的音视频通话房间，和主播连麦互动。</p>
</blockquote>

<p>网易云互动直播地址:<a href="https://www.163yun.com/product/interact">https://www.163yun.com/product/interact</a></p>

<h1 id="toc_6">二. 腾讯云 互动直播ILVB</h1>

<blockquote>
<p>互动直播（Interactive Live Video Broadcasting）是全新的一站式“多路音视频互动”解决方案，主打“连麦”、“多画面特效”等能力；通过客户端SDK可打造跨平台一对多，多对多（支持最大同时<strong>8</strong>人上麦）的超清酷炫直播场景</p>
</blockquote>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-2e9adb38e8fa79b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午1.50.15.png"/></p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-70b7b469c6e2cd0f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午1.51.20.png"/></p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-3380c4ef7ee31fb1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午1.53.40.png"/></p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-39dc0cb9cb7963dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午1.59.56.png"/></p>

<p><strong>数据交互时序说明</strong></p>

<pre><code>步骤1和2解释了独立帐号模式下，app用户完成腾讯互动直播身份认证的过程。

如果采用托管帐号模式，则不需要开发者server参与，直接调互动直播sdk login接口即可；
开播、观看、上麦等音视频接口的调用必须在进房间成功之后；
只要app业务逻辑允许，在调用相应的接口后，任何用户都有上麦能力；
开发者后台server可以通过腾讯互动直播给app里的用户或者群组push消息。
</code></pre>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-3fa0edd5258cff74.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午2.01.36.png"/></p>

<h4 id="toc_7">后台接口已实现的功能</h4>

<blockquote>
<p>注册<br/>
    登录<br/>
    创建房间<br/>
    上报创建房间结果<br/>
    拉取直播房间列表<br/>
    上报进入房间信息<br/>
    拉取房间成员列表<br/>
    心跳上报<br/>
    申请上麦<br/>
    申请上麦结果上报<br/>
    录制视频完成上报<br/>
    退出房间<br/>
    拉取点播列表<br/>
    拉取旁路直播地址列表<br/>
    拉取指定房间的旁路直播地址<br/>
    下线</p>
</blockquote>

<h4 id="toc_8">客户端开启直播接口流程:</h4>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-85bc4166c86ea4e9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午2.06.47.png"/></p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-1aebc166c9efbf5a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午2.07.17.png"/></p>

<p>腾讯云互动直播地址:<a href="https://cloud.tencent.com/document/product/268">https://cloud.tencent.com/document/product/268</a><br/>
价格地址:<a href="https://cloud.tencent.com/document/product/268/5127">https://cloud.tencent.com/document/product/268/5127</a></p>

<h1 id="toc_9">三. 阿里云直播</h1>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-20b86d34a12214b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午2.10.07.png"/></p>

<h5 id="toc_10">连麦介绍:</h5>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-a69c2696e42d1554.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-27 下午2.14.32.png"/></p>

<blockquote>
<p>连麦服务提供接入测试操作，可通过连麦参数配置接入连麦服务，测试阶段连麦服务做多支持5路连麦并发流。如果您想接入阿里云连麦服务，请与客户服务人员联系或提交工单申请。<br/>
阿里云连麦服务提供简单的配置，开通过程包括以下步骤<br/>
Step 1: 添加直播加速域名<br/>
Step 2: 创建连麦服务<br/>
Step 3：配置回调地址</p>
</blockquote>

<h5 id="toc_11">连麦参与者的职责和功能</h5>

<h6 id="toc_12">主播端</h6>

<blockquote>
<p>采集音视频信号并编码、推送直播流。<br/>
拉取副麦端的直播流。<br/>
将拉取的副麦端的直播流与本地采集的视频进行叠加播放。</p>
</blockquote>

<h6 id="toc_13">副麦端</h6>

<blockquote>
<p>采集音视频信号并编码、推送直播流。<br/>
拉取主播及其他副麦端的直播流。<br/>
将拉取的直播流与本地采集的视频进行叠加播放。</p>
</blockquote>

<h6 id="toc_14">观众端</h6>

<blockquote>
<p>播放混流地址中的直播流</p>
</blockquote>

<h6 id="toc_15">APP Server</h6>

<blockquote>
<p>管理直播或连麦过程中使用的地址，包括推流地址、播放地址和混流地址。<br/>
对直播或连麦业务进行管理<br/>
调用AliLive的混流接口和接受AliLive的回调，以实现服务端混流的功能。</p>
</blockquote>

<h6 id="toc_16">AliLive</h6>

<blockquote>
<p>接受直播流的推送<br/>
接受直播流的拉取<br/>
将多路直播流混合成一路，并输出<br/>
接受混合后的直播流的拉取</p>
</blockquote>

<h6 id="toc_17">注：</h6>

<blockquote>
<p>连麦过程中APP Server需要提供三类地址：推流地址、播放地址、混流地址。<br/>
1   推流地址是直播或副麦推送直播流的地址，仅供主播端和副麦端使用。<br/>
2   播放地址是用于观看主播或副麦的直播视频的地址，仅在连麦的过程中使用，且仅供主播端和副麦端使用。<br/>
3   混流地址是用于观看AliLive混合多路直播流的结果的地址，仅供观众端使用。混流地址可以在非连麦的过程中使用，此时播放的就是主播的画面（与主播的播放地址内容相同）；若在连麦过程中使用，播放的就是主播与副麦的混合画面。<br/>
4  观众播放的一定是混流地址。当观众参与连麦、成为副麦时，会结束混流地址的播放，并开始播放主播和其他副麦的直播地址；当副麦结束连麦、成为观众时，会结束播放主播和其他副麦的直播地址，重新开始播放混流地址。</p>
</blockquote>

<h5 id="toc_18">连麦的参与者</h5>

<p>连麦的过程有5种参与者：</p>

<blockquote>
<p>主播端：<br/>
主播的客户端。<br/>
副麦端：<br/>
正在与主播连麦的人的客户端。<br/>
观众端：<br/>
未参与连麦的、观看直播或他人连麦的人的客户端。<br/>
APP Server：<br/>
用于接收或转发连麦信号的服务端，由直播业务方自行开发，可以根据自身的业务逻辑来控制连麦的流程，也是混流功能的唯一调用方。<br/>
AliLive：<br/>
阿里云直播服务器，提供整个直播或连麦过程中所有直播流的接收、分发和混流服务。<br/>
注：当观众开始连麦后，我们称之为副麦；当副麦结束连麦后，我们称之为观众。</p>
</blockquote>

<h4 id="toc_19">典型业务流程</h4>

<pre><code>
本小节将描述一个典型业务流程的实线逻辑，从主播上线到观众加入连麦、连麦结束，最后主播退出直播为止。

主播发起直播与观众观看直播

    主播向APP Server发起直播请求。
    APP Server同意主播发起直播，并分配主播的推流地址、播放地址以及混流地址。
    主播通过推流地址开始推流。
    APP Server收到AliLive推流成功的回调，将主播放入直播列表，表示此时观众可以播放主播的直播流。
    观众A、B、C开始观看直播（即播放混流地址）。
    通知AppServer,用户A、B、C正在观看

主播发起连麦

    主播向APP Server发出请求，希望与观众A、B连麦。
    APP Server向观众A、B反馈主播的请求。
    观众A、B向APP Server发送同意主播连麦请求的信号。
    APP Server向观众A、B分配各自的推流地址，并发送主播流的播放地址。
    观众A、B开始连麦（即结束播放混流地址，开始推流、开始播放主播的播放地址）。
    APP Server收到AliLive给出的观众A、B推流成功的回调，将A、B的播放地址发送给主播和A、B、C。（注释1：此处观众C并不需要收到A、B的播放地址，是否收到A、B的播放地址对于观众C的播放没有任何影响。之所以收到这个消息主要是通知第三方观众有人加入连麦了。）
    主播开始与A、B进行连麦（即播放A、B的播放地址）。
    副麦A增加与B的连麦（即播放B的播放地址）。
    副麦B增加与A的连麦（即播放A的播放地址）。
    APP Server调用AliLive的混流接口，开始混流且A、B加入混流画面。至此，主播与A、B连麦成功。

副麦退出连麦

    副麦B向APP Server发送结束连麦的通知，然后结束连麦（即停止推流、停止播放主播和副麦A的播放地址，开始播放混流地址）。
    APP Server调用AliLive的混流接口，B退出混流画面
    APP Server发送副麦B退出直播的消息给主播及A、B、C。
    主播与B停止连麦（即结束播放B的播放地址）。
    副麦A与B停止连麦（即结束播放B的播放地址）。 

观众加入连麦

    观众C向APP Server发出申请，要求加入连麦。
    APP Server向主播和副麦A转发观众C的申请。
    主播和副麦A向APP Server发送同意连麦的信号。
    APP Server向观众C分配推流地址，并发送主播和副麦A的播放地址。
    观众C开始连麦（即结束播放混流地址，开始推流、开始播放主播和副麦A的播放地址）。
    APP Server收到AliLive给出的观众C推流成功的回调，将C的播放地址发送给主播和A、B、C。
    主播增加与C的连麦（即播放C的播放地址）。
    副麦A增加与C的连麦（即播放C的播放地址）。
    APP Server调用AliLive的混流接口，C加入混流画面。至此，观众C加入连麦成功。

主播终止连麦

    主播向APP Server发送终止连麦通知，并终止连麦（即结束播放副麦A、C的播放地址）。
    APP Server向主播和A、B、C发送终止连麦的信号。
    副麦A退出连麦（即结束推流、结束播放主播和副麦C的播放地址，开始播放混流地址）。
    副麦C退出连麦（即结束推流、结束播放主播和副麦A的播放地址，开始播放混流地址）。
    APP Server调用AliLive的混流接口，结束混流，A、C退出混流画面。至此，连麦终止。

主播结束直播

    主播向APP Server发送结束直播的通知，并结束推流。
    APP Server向观众A、B、C告知直播结束。
    观众A、B、C退出直播（即结束播放混流地址）。

注：无论是直播还是连麦的过程，推流是不可缺少的。主播会推流，副麦会推流。客户端SDK中就提供了能够实现推流功能的接口，这些接口中所谓的推流成功指的是直播流可以成功的发送出去。但这并不表示此时可以从服务端下载这些直播流并观看，只有收到AliLive中推流成功的回调后，才表示可以真正开始播放。
</code></pre>

<h4 id="toc_20">连麦服务开通与配置</h4>

<blockquote>
<p>I：提供需要连麦的域名和APP（连麦需要消耗大量服务端资源，业务上需要将连麦与非连麦的业务区分）<br/>
II：提供连麦的估计并发量<br/>
III：提供混流回调URL：混流可用回调和混流结果回调<br/>
IV：将上述三个信息提供给阿里云相关人员<br/>
V：在阿里云控制台上配置直播推断流回调</p>
</blockquote>

<p>阿里云连麦文档地址:<a href="https://help.aliyun.com/document_detail/52350.html?spm=5176.doc29951.6.650.DNEVno">https://help.aliyun.com/document_detail/52350.html?spm=5176.doc29951.6.650.DNEVno</a><br/>
价格地址:<a href="https://cn.aliyun.com/price/product#/live/detail">https://cn.aliyun.com/price/product#/live/detail</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mac电脑清理存储空间]]></title>
    <link href="www.freefook.com/15139218767623.html"/>
    <updated>2017-12-22T13:51:16+08:00</updated>
    <id>www.freefook.com/15139218767623.html</id>
    <content type="html"><![CDATA[
<p>由于今天提示空间不足1G不得不来清理一下空间</p>

<h3 id="toc_0">清理后的空间:</h3>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-f0d2bd53eb590038.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""/></p>

<h3 id="toc_1">以下诉说的是120G的悲伤</h3>

<h4 id="toc_2">第一步:先看一下那个文件目录下空间使用</h4>

<p>sudo du -sh /*</p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-742477290ff2ea3b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""/></p>

<p>如果你使用xcode 可以做如下操作获得更多的空闲存储空间</p>

<h4 id="toc_3">操作1 :xcode移除DerivedData</h4>

<p>可重新生成；会删除build生成的项目索引、build输出以及日志。<br/>
路径：~/Library/Developer/Xcode/DerivedData</p>

<h4 id="toc_4">操作2 :删除DeviceSupport</h4>

<p>如果你是128G的本子,用xcode开发,空间不足时,<br/>
删除DeviceSupport里的吧,留两个自己经常使用的就够了<br/>
~/Library/Developer/Xcode/iOS DeviceSupport</p>

<h4 id="toc_5">操作3 :清除缓存文件</h4>

<p>cd ~/Library/Caches/<br/>
rm -rf ~/Library/Caches/*<br/>
不用命令行方式:<br/>
<img src="http://upload-images.jianshu.io/upload_images/670820-fe787cb2173e93c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""/></p>

<p>点击前往文件夹,输入:~/Library/Caches/<br/>
就看到文件目录了,删除caches下的文件即可;</p>

<h4 id="toc_6">操作4 :删除所有系统日志</h4>

<p>可以使用下面的命令删除：<br/>
sudo rm -rf /private/var/log/*<br/>
也可以在操作6中截图的路径文件夹看到Log文件夹,删除下面的文件就可以;</p>

<h4 id="toc_7">操作5 :删除临时文件路径</h4>

<p>cd /private/var/tmp/<br/>
也可以在操作6中截图的路径文件夹看到tmp文件夹,删除下面的文件就可以;</p>

<h4 id="toc_8">操作6 :禁用SafeSleep休眠模式</h4>

<p>当升级到OS X 10.9 Mavericks版本之后，显示隐藏文件命令如下：<br/>
//显示隐藏文件<br/>
defaults write com.apple.finder AppleShowAllFiles Yes &amp;&amp; killall Finder <br/>
//不显示隐藏文件<br/>
defaults write com.apple.finder AppleShowAllFiles No &amp;&amp; killall Finder </p>

<p>显示隐藏文件对照截图目录寻找<br/>
<img src="http://upload-images.jianshu.io/upload_images/670820-baedb9fac879bcb0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""/></p>

<p>防止OS X继续创建该文件，所以我们需要下面的命令生成一个无法被替换的空文件<br/>
1  touch sleepimage<br/>
2  chmod 000 /private/var/vm/sleepimage<br/>
如果你想要重新开启SafeSleep功能，只需下面的命令即可<br/>
1  sudo pmset -a hibernatemode 3<br/>
2  sudo rm /private/var/vm/sleepimage</p>

<h4 id="toc_9">操作7 :停止TimeMachine本地备份（这个看你个人喜欢）</h4>

<p>sudo tmutil disablelocal</p>

<h4 id="toc_10">操作8 :嗓音文件删除</h4>

<p>如果你不适用文字转语音功能，那么你肯定不会使用到OS X内置的嗓音文件。<br/>
你可以删除这些文件重新获得硬盘空间。<br/>
在终端应用中，使用下面的命令即可，首先定位到文件所在文件夹：<br/>
cd /System/Library/Speech/<br/>
然后执行删除命令，将所有嗓音文件删除<br/>
sudo rm -rf Voices/*<br/>
如果你执行了命令，那么你将无法使用系统的文字转语音功能。</p>

<h4 id="toc_11">操作9 :不建议尝试</h4>

<p>通过下面的命令移除缓存代码：<br/>
sudo rm -rf /private/var/folders/<br/>
但是别清除,出错了你又不知道怎么改好;</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS  MQTT 接入示例]]></title>
    <link href="www.freefook.com/15139218580826.html"/>
    <updated>2017-12-22T13:50:58+08:00</updated>
    <id>www.freefook.com/15139218580826.html</id>
    <content type="html"><![CDATA[
<h4 id="toc_0">前言</h4>

<blockquote>
<p>需求是移动端接入MQTT,点击按钮利用MQTT给门禁上的设备发送消息;<br/>
注:门禁设备(Android系统集成了MQTT和给硬件信息发送指令的包)<br/>
缺陷未解决: <br/>
1.门最后开没开成功,硬件是没有给反馈的,门禁设备也不知道;<br/>
2.移动设备消息发送了,指定的门禁设备是否收到消息,移动端还不知道;</p>

<p>该文介绍的是使用阿里的MQTT接入ios的说明<br/>
因给的demo里没有参数说明,看👇简单说明作为了解;</p>
</blockquote>

<h4 id="toc_1">MQTT协议中文版</h4>

<blockquote>
<p>MQTT是一个客户端服务端架构的发布/订阅模式的消息传输协议。它的设计思想是轻巧、开放、简单、规范，易于实现。<br/>
这些特点使得它对很多场景来说都是很好的选择，特别是对于受限的环境如机器与机器的通信（M2M）以及物联网环境（IoT）<br/>
协议传送门:<a href="https://mcxiaoke.gitbooks.io/mqtt-cn/content/">https://mcxiaoke.gitbooks.io/mqtt-cn/content/</a></p>
</blockquote>

<h4 id="toc_2">MQTT应用场景</h4>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-a120f71ecd76f2e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照.png"/></p>

<h4 id="toc_3">MQTT 物联套件</h4>

<p>介绍 MQTT 协议基本概念，阿里巴巴 MQ 提供的 MQTT 服务的主要原理以及 MQTT 协议主要的应用场景<br/>
地址如下:<br/>
<a href="https://help.aliyun.com/document_detail/42419.html?spm=5176.doc47755.6.560.dcabYu">https://help.aliyun.com/document_detail/42419.html?spm=5176.doc47755.6.560.dcabYu</a></p>

<h4 id="toc_4">MQTT iOS 接入示例</h4>

<p>介绍如何使用 iOS 客户端收发 MQTT 消息地址如下:<br/>
<a href="https://help.aliyun.com/document_detail/47755.html?spm=5176.doc44711.6.633.pN8AIa">https://help.aliyun.com/document_detail/47755.html?spm=5176.doc44711.6.633.pN8AIa</a></p>

<h4 id="toc_5">iOS接入 非CocoaPods 安装配置</h4>

<p>滑动到👆示例地址的底部: 下载demo  拿到路径pods下的MQTTClient下的MQTTClient导入工程;<br/>
不要将LICENSE文件也导入进程序</p>

<h6 id="toc_6">不是CocoaPods安装,需要将如下头文件改成双引号&quot;&quot;</h6>

<pre><code>#import &lt;MQTTClient/MQTTSession.h&gt;
#import &lt;MQTTClient/MQTTSessionLegacy.h&gt;
#import &lt;MQTTClient/MQTTSessionSynchron.h&gt;
#import &lt;MQTTClient/MQTTMessage.h&gt;
#import &lt;MQTTClient/MQTTTransport.h&gt;
#import &lt;MQTTClient/MQTTCFSocketTransport.h&gt;
#import &lt;MQTTClient/MQTTCoreDataPersistence.h&gt;
#import &lt;MQTTClient/MQTTSSLSecurityPolicyTransport.h&gt;
</code></pre>

<pre><code>#import &quot;MQTTSession.h&quot;
#import &quot;MQTTSessionLegacy.h&quot;
#import &quot;MQTTSessionSynchron.h&quot;
#import &quot;MQTTMessage.h&quot;
#import &quot;MQTTTransport.h&quot;
#import &quot;MQTTCFSocketTransport.h&quot;
#import &quot;MQTTCoreDataPersistence.h&quot;
#import &quot;MQTTSSLSecurityPolicyTransport.h&quot;
</code></pre>

<h6 id="toc_7">在需要实现的地方导入头文件;</h6>

<pre><code>/*
 * MQTTClient: imports
 * MQTTSessionManager.h is optional
 */
#import &quot;MQTTClient.h&quot;
#import &quot;MQTTSessionManager.h&quot;

/*
 * MQTTClient: using your main view controller as the MQTTSessionManagerDelegate
 */

#import &lt;CommonCrypto/CommonHMAC.h&gt;
</code></pre>

<h6 id="toc_8">添加代理:</h6>

<pre><code>MQTTSessionManagerDelegate
</code></pre>

<pre><code>/*
 * MQTTClient: keep a strong reference to your MQTTSessionManager here
 */
@property (strong, nonatomic) MQTTSessionManager *manager;

@property (strong, nonatomic) NSDictionary *mqttSettings;
@property (strong, nonatomic) NSString *rootTopic;
@property (strong, nonatomic) NSString *accessKey;
@property (strong, nonatomic) NSString *secretKey;
@property (strong, nonatomic) NSString *groupId;
@property (strong, nonatomic) NSString *clientId;
@property (assign, nonatomic) NSInteger qos;

@property (strong, nonatomic) NSMutableArray *chat;
</code></pre>

<h6 id="toc_9">初始化客户端连接到host</h6>

<pre><code> MQTT-Client-FrameWork 包提供的客户端类有 MQTTSession 和 MQTTSessionManager，
 建议使用后者维持静态资源，而且已经封装好自动重连等逻辑。
 初始化时需要传入相关的网络参数
</code></pre>

<p>参数在阿里提供的demo里有一个plist文件,如下:</p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-a7797966c33937f0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017.png"/></p>

<p>参数如何配置请查看👇:<br/>
<a href="https://help.aliyun.com/document_detail/29536.html?spm=5176.doc29535.6.551.OrrVHX">https://help.aliyun.com/document_detail/29536.html?spm=5176.doc29535.6.551.OrrVHX</a></p>

<h4 id="toc_10">从配置文件导入相关属性,发起连接</h4>

<p>我的需求是只有一个地方使用,进到这个页面的时候,我才发起连接,<br/>
点击按钮给门禁上的java程序发送开门消息,连接方法调用如下方法:<br/>
```<br/>
-(void)initMQTT{</p>

<pre><code>NSURL *bundleURL = [[NSBundle mainBundle] bundleURL];
NSURL *mqttPlistUrl = [bundleURL URLByAppendingPathComponent:@&quot;mqtt.plist&quot;];
self.mqttSettings = [NSDictionary dictionaryWithContentsOfURL:mqttPlistUrl];
self.rootTopic = self.mqttSettings[@&quot;rootTopic&quot;];
self.accessKey = self.mqttSettings[@&quot;accessKey&quot;];
self.secretKey = self.mqttSettings[@&quot;secretKey&quot;];
self.groupId = self.mqttSettings[@&quot;groupId&quot;];
self.qos =[self.mqttSettings[@&quot;qos&quot;] integerValue];

//clientId的生成必须遵循GroupID@@@前缀，且需要保证全局唯一
/*为了保证全局唯一,ios可以获取CFUUID,每次获取都是不一样的,
   想保证一个设备一样,需要存本地一份;
    但是我这里需要每次使用的时候,每次连击所以为了保证clientid全局唯一,
    我每次都获取一次CFUUID,去掉中间的分隔线&quot; - &quot;代码如下,
*/
CFUUIDRef cfuuid = CFUUIDCreate(kCFAllocatorDefault);
NSString* cfuuidString = (NSString*)CFBridgingRelease(CFUUIDCreateString(kCFAllocatorDefault, cfuuid));
NSString* tempstr = [cfuuidString stringByReplacingOccurrencesOfString:@&quot;-&quot; withString:@&quot;&quot;];
cfuuidString = tempstr;

self.clientId=[NSString stringWithFormat:@&quot;%@@@@%@%@&quot;,self.groupId,@&quot;&quot;,cfuuidString];

self.chat = [[NSMutableArray alloc] init];
/*
 * MQTTClient: create an instance of MQTTSessionManager once and connect
 * will is set to let the broker indicate to other subscribers if the connection is lost
 */
if (!self.manager) {
    self.manager = [[MQTTSessionManager alloc] init];
    self.manager.delegate = self;

    self.manager.subscriptions = [NSDictionary dictionaryWithObject:
                                  [NSNumber numberWithLong:self.qos]forKey:
                                  [NSString stringWithFormat:@&quot;%@/#&quot;, self.rootTopic]];

    //password的计算方式是，使用secretkey对groupId做hmac签名算法，具体实现参考macSignWithText方法
    NSString *passWord = [[self class] macSignWithText:self.groupId secretKey:self.secretKey];
      /*
      此处从配置文件导入的Host即为MQTT的接入点，该接入点获取方式请参考资源申请章节文档，
       在控制台上申请MQTT实例，每个实例会分配一个接入点域名
      */
    [self.manager connectTo:self.mqttSettings[@&quot;host&quot;]
                       port:[self.mqttSettings[@&quot;port&quot;] intValue]
                        tls:[self.mqttSettings[@&quot;tls&quot;] boolValue]
                  keepalive:60  //心跳间隔不得大于120s
                      clean:true
                       auth:true
                       user:self.accessKey
                       pass:passWord
                       will:false
                  willTopic:nil
                    willMsg:nil
                    willQos:0
             willRetainFlag:FALSE
               withClientId:self.clientId];

} else {
    [self.manager connectToLast];
}
</code></pre>

<p>}</p>

<p>/*<br/>
 userName 和 passWord 的设置</p>

<p>由于服务端需要对客户端进行鉴权，因此需要传入合法的 userName 和 passWord。<br/>
 userName 设置为当前用户的 AccessKey，<br/>
 password 则设置为 MQTT 客户端 GroupID 的签名字符串，<br/>
 签名计算方式是使用 SecretKey 对 GroupID 做 HmacSHA1 散列加密。<br/>
 具体方法请参考 👇 中的 macSignWithText 函数。<br/>
 */<br/>
+ (NSString *)macSignWithText:(NSString *)text secretKey:(NSString *)secretKey<br/>
{<br/>
    NSData *saltData = [secretKey dataUsingEncoding:NSUTF8StringEncoding];<br/>
    NSData <em>paramData = [text dataUsingEncoding:NSUTF8StringEncoding];<br/>
    NSMutableData</em> hash = [NSMutableData dataWithLength:CC_SHA1_DIGEST_LENGTH ];<br/>
    CCHmac(kCCHmacAlgSHA1, saltData.bytes, saltData.length, paramData.bytes, paramData.length, hash.mutableBytes);<br/>
    NSString *base64Hash = [hash base64EncodedStringWithOptions:0];</p>

<pre><code>return base64Hash;
</code></pre>

<p>}</p>

<pre><code>#####connectTo方法里的参数说明:
 &gt;  * tls:false //是否使用tls协议，mosca是支持tls的，如果使用了要设置成true
 *  clean:false //session是否清除，这个需要注意，如果是false，代表保持登录，
     如果客户端离线了再次登录就可以接收到离线消息。注意：QoS为1和QoS为2，并需订阅和发送一致
 *  auth:true //是否使用登录验证，和下面的user和pass参数组合使用
 * user:_userName //用户名
 * pass:_passwd //密码
 * willTopic:@&quot;&quot; //下面四个参数用来设置如果客户端异常离线发送的消息，
    当前参数是哪个topic用来传输异常离线消息，这里的异常离线消息都指的是客户端掉线后发送的掉线消息
 * will:@&quot;&quot; //异常离线消息体。自定义的异常离线消息，约定好格式就可以了
 * willQos:0 //接收离线消息的级别 0、1、2
 * willRetainFlag:false //只有在为true时，Will Qos和Will Retain才会被读取，此时消息体payload中
     要出现Will Topic和Will   Message具体内容，否则，Will QoS和Will Retain值会被忽略掉
 * withClientId:nil]; //客户端id，需要特别指出的是这个id需要全局唯一，因为服务端是根据这个来区分不同的客户端的，
    默认情况下一个id登录后，假如有另外的连接以这个id登录，上一个连接会被踢下线;

####发送消息(当点击按钮的时候,发送消息方法如下:)
</code></pre>

<p>[self.manager sendData:[self.scanDic.mj_JSONString dataUsingEncoding:NSUTF8StringEncoding]<br/>
                     topic:[NSString stringWithFormat:@&quot;%@&quot;,<br/>
                            self.rootTopic]//此处设置多级子topic<br/>
                       qos:self.qos<br/>
                    retain:FALSE];<br/>
```</p>

<h5 id="toc_11">发送方法注意topic的设置</h5>

<blockquote>
<p>以下为安卓代码中的注释示例:<br/>
ios的demo中没有此说明<br/>
消息发送到某个主题Topic，所有订阅这个Topic的设备都能收到这个消息。<br/>
遵循MQTT的发布订阅规范，Topic也可以是多级Topic。<br/>
此处设置了发送到二级topic如下:<br/>
 sampleClient.publish(topic+&quot;/notice/&quot;, message);<br/>
但是发送P2P消息，二级Topic必须是“p2p”,三级topic是目标的ClientID<br/>
 此处设置的三级topic需要是接收方的ClientID如下:<br/>
 string p2pTopic =topic+&quot;/p2p/&quot;+consumerClientId;</p>
</blockquote>

<h5 id="toc_12">qos:消息的传输方式</h5>

<blockquote>
<p>QoS说明如下：<br/>
   *  0    代表“至多一次”，消息发布完全依赖底层 TCP/IP 网络。会发生消息丢失或重复。<br/>
     这一级别可用于如下情况，环境传感器数据，丢失一次读记录无所谓，因为不久后还会有第二次发送。<br/>
   *  1   代表“至少一次”，确保消息到达，但消息重复可能会发生。<br/>
   *  2   代表“只有一次”，确保消息到达一次。这一级别可用于如下情况，在计费系统中，消息重复或丢失会导致不正确的结果。 <br/>
   * 备注：由于服务端采用Mosca实现，Mosca目前只支持到QoS 1<br/>
   * 如果发送的是临时的消息，例如:给某topic所有在线的设备发送一条消息，丢失的话也无所谓，0就可以了<br/>
（客户端登录的时候要指明支持的QoS级别，同时发送消息的时候也要指明这条消息支持的QoS级别)<br/>
   * 如果需要客户端保证能接收消息，需要指定QoS为1，如果同时需要加入客户端不在线也要能接收到消息，<br/>
   那么客户端登录的时候要指定session的有效性，接收离线消息需要指定服务端要保留客户端的session状态。</p>
</blockquote>

<h4 id="toc_13">接收发送消息的回调</h4>

<pre><code>/*
 * MQTTSessionManagerDelegate
 */
- (void)handleMessage:(NSData *)data onTopic:(NSString *)topic retained:(BOOL)retained {
    /*
     * MQTTClient: process received message
     */
    NSString *dataString = [[NSString alloc] initWithData:data encoding:NSUTF8StringEncoding];
    [self.chat insertObject:[NSString stringWithFormat:@&quot;RecvMsg from Topic: %@\nBody: %@&quot;, topic, dataString] atIndex:0];    
}

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AR 原理与技术分析]]></title>
    <link href="www.freefook.com/15139218050505.html"/>
    <updated>2017-12-22T13:50:05+08:00</updated>
    <id>www.freefook.com/15139218050505.html</id>
    <content type="html"><![CDATA[
<h1 id="toc_0">开发场景介绍:</h1>

<p>开发场景介绍摘自电脑爱好者2016年21期<br/>
<img src="http://upload-images.jianshu.io/upload_images/670820-d5e156910b67f395.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""/></p>

<p>AR可以让用户在扫描特定的图片、二维码时展现相应的视频场景，<br/>
那么这种特效是怎么实现的？<br/>
先来了解一下AR程序运行流程是怎么样的?<br/>
<code><br/>
开启手机摄像头对准特定的宣传画扫描，<br/>
接着手机屏幕上就会出现和相应产品对应的自然元素组成的视频。<br/>
这个视频展现，其实就是一个典型AR场景的再现<br/>
</code></p>

<h2 id="toc_1">AR效果的实现</h2>

<h3 id="toc_2">第一步:</h3>

<blockquote>
<p>制作方要对扫描的实物进行建模。<br/>
我们需要先扫描该物品的3D模型，并对其进行关键帧标定，<br/>
比如:瓶盖、瓶身某位置或者图片的不同画面,<br/>
然后根据不同的识别准备对应的动态视频数据 </p>
</blockquote>

<h3 id="toc_3">第二步:</h3>

<blockquote>
<p>当扫描标定的关键帧,系统就会去寻找AR场景中与之最接近的关键帧，<br/>
根据关键帧上的特征点，然后利用特定的算法找到AR场景中对应的视频，<br/>
并将其展现在用户的手机画面中;</p>
</blockquote>

<h3 id="toc_4">关键技术:&lt;识别跟踪&gt;</h3>

<blockquote>
<p>在这个AR应用中技术核心就是&lt;识别跟踪&gt;技术，<br/>
AR应用首先要识别标示物，然后进行跟踪（跟踪用户扫描到的产品标记)，<br/>
接着就在用户手机上展示对应的视频场景。</p>

<p>AR应用是通过“特征点”进行识别的;<br/>
检测到特征点还不行，如果要判断两张图片是否是同一张图片，<br/>
识别设备还要判断两张图片的特征点是否一致;</p>
</blockquote>

<p>识别技术不在介绍,(开发时这里了解,不做过多陈述,我也不懂)</p>

<h3 id="toc_5">第三步: AR视频是由多帧图片组成</h3>

<blockquote>
<p>在完成一幅图片的比对后还要对视频帧的其他图片进行跟踪比对。<br/>
特征跟踪有两种方式:<br/>
一种是对视频流中的每一帧图像进行特征点匹配;<br/>
二种则在第一幅图像中，寻找可能的特征位置<br/>
然后在后续的图像中搜索它们的对应位置。<br/>
这样完成对识别图片的跟踪后，<br/>
AR应用就会在用户的手机上显现对应的视频画面了。</p>
</blockquote>

<h3 id="toc_6">最后:</h3>

<blockquote>
<p>AR应用会先将图片进行特征点的识别，并存储在应用中。<br/>
这样当用户使用手机扫描到符合特征点的瓶身图片，<br/>
AR应用会将当前图片和存储的图片进行比对，如果是一致的图片，<br/>
AR应用就会将特定的视频展示在用户手机屏幕上。<br/>
当然AR应用还会进行跟踪，如扫描不同的区域显示不同的视频，<br/>
或者在扫描其他图片时快速识别并显示预置的视频到用户手机上。 </p>
</blockquote>

<hr/>

<h6 id="toc_7">ARinChina地址:汇总了一些资源👇传送门:</h6>

<p><a href="http://dev.arinchina.com/forum.php">http://dev.arinchina.com/forum.php</a></p>

<h1 id="toc_8">AR原理篇,带你增强现实的思路</h1>

<p>(摘自)[AR报告第二章：AR的工作原理]脑补画面</p>

<h5 id="toc_9">1   首先对现实场景的理解和重构</h5>

<blockquote>
<p>在AR(增强现实)系统中<br/>
首先要解决“是什么”的问题，<br/>
也就是要理解、知道场景中存在什么样的对象和目标。<br/>
第二要解决“在哪里”的问题，也就是要对场景结构进行分析，<br/>
实现跟踪定位和场景重构。</p>
</blockquote>

<h5 id="toc_10">2   物体的检测和识别技术</h5>

<blockquote>
<p>物体检测和识别的目的是发现并找到场景中的目标，<br/>
这是场景理解中的关键一环。<br/>
广义的物体检测和识别技术是基于:<br/>
&quot;图像&quot;的基本信息（各类型特征）和先验知识模型（物体信息表示)<br/>
通过相关的算法实现对场景内容分析的过程。</p>
</blockquote>

<p>(开发中可能遇到需要识别图片的场景,但是算法不是自己写,就先别管怎么识别出来啦)<br/>
<code><br/>
在增强现实领域，常见的检测和识别任务有，<br/>
人脸检测、<br/>
行人检测、<br/>
车辆检测、<br/>
手势识别、<br/>
生物识别、<br/>
情感识别、<br/>
自然场景识别等<br/>
</code><br/>
<strong>这里我只提取介绍一种图像识别:</strong></p>

<blockquote>
<p>识别是从图像匹配的角度出发，<br/>
数据库中保存了图像的特征以及对应的标注信息，<br/>
在实际使用过程中，通过图像匹配的方法找到最相关的图像，<br/>
从而定位环境中的目标，进一步得到识别图像和目标图像的精确位置，<br/>
这种识别适用于需要对环境进行精确跟踪的应用场景</p>
</blockquote>

<p>(开发经常使用的识别图片,其他需要智能识别这里不做介绍);</p>

<p>另一方面，图像本身还受到噪声、尺度、旋转、光照、姿态等因素的影响</p>

<h5 id="toc_11">视觉跟踪技术</h5>

<blockquote>
<p>根据数据的生成方式，视觉跟踪技术的算法可以分为两种，<br/>
一种是基于模板匹配的方式，<br/>
预先对需要跟踪的target进行训练，<br/>
在跟踪阶段通过不断的跟预存训练数据进行比对 解算当前的位姿。<br/>
这类方法的好处是速度较快、数据量小、系统简单，适用于一些特定的场景，<br/>
但不适用于大范围的场景</p>
</blockquote>

<p>另外一种是SLAM方法，也就是即时定位和地图构建技术。(不做介绍)</p>

<h5 id="toc_12">3   增强现实的显示技术</h5>

<p>摄像头获取外部真实环境的图像，<br/>
也就是通过摄像头来采集真实场景的图像进行传递。<br/>
计算机通过场景理解和分析将所要添加的信息和图像信号叠加<br/>
在摄像机的视频信号上，将计算机生成的虚拟场景与真实场景进行融合</p>

<hr/>

<h1 id="toc_13">实现篇:</h1>

<p>现在不少移动端加入了AR的功能作为功能的拓展与补充。<br/>
如淘宝过年期间的AR福字扫描，人脸识别，还有一个AR的游戏等等。<br/>
那么我们今天就说几个可以在移动端实现AR功能的解决方案。</p>

<p><strong>AR在开发ios的时候使用Xcode+Realmax SDK，<br/>
也可以使用Unity+Realmax SDK开发导成api，再导入Xcode编译;</strong></p>

<p><strong>注:需要跨平台使用实现那些炫酷效果需要使用unity来做;</strong></p>

<p>这里没尝试,不懂,再此先不做介绍;研究了补充上说明文档;</p>

<h5 id="toc_14">解决方案</h5>

<p>1 利用第三方AR开发包去实现。</p>

<p>时至今日，AR技术有了一定的发展，<br/>
可以利用第三方的framework开发包导入工程来实现。<br/>
支持的SDK:Metaio被苹果收购、Vuforia被高通（Qualcomm）卖给PTC后，<br/>
相对较好的有ARToolKit、Wikitude</p>

<p>国外的介绍高通的AR实现方案<br/>
在高通VR的官网 :<a href="https://developer.vuforia.com/">https://developer.vuforia.com/</a><br/>
有关识别后显示3D物体，video等的一些基础与高级识别结果<br/>
<code><br/>
注:本着能不看英文就不看英文的想法,可以跳过高通的方案;<br/>
</code></p>

<p>不过国内也有不错的一个国内的引擎：EasyAR<br/>
国内的有easyAR 地址: <a href="http://www.easyar.cn/">http://www.easyar.cn/</a><br/>
<code><br/>
文档和demo真的是干净,没有什么注释说明,<br/>
刚刚接触的使用xcode打开demo看起来是不是一脸懵逼,<br/>
没事不用懂代码都什么东西,使用unity配置好,玩玩导出ios的就可以了....<br/>
</code></p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-6f9a9265b8beb57d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-26 上午9.24.36.png"/></p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-aeb0ccb754fe66e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2017-05-26 上午9.26.01.png"/></p>

<p>(👇图是博客园里的盗图,如有雷同是我抄袭,如果看到原出处,请告知,谢谢)<br/>
图片地址:<a href="http://www.cnblogs.com/guanshenbao/p/5744407.html">http://www.cnblogs.com/guanshenbao/p/5744407.html</a></p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-295e1c21bd20fe7c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"/></p>

<p>看到👆的图,应该就能猜测到,需要识别的图,<br/>
和识别之后显示的酷炫效果是需要使用unity来制作的;</p>

<blockquote>
<p>EasyAR跟高通AR有类似的功能，两者的操作方法略有不同，<br/>
高通需要把图片传到其网站上的，<br/>
而easyAR是可以直接在工程上替换想要识别的图片的，(识别的图片)<br/>
所以说在设定识别图片的方便度上，<br/>
easyAR要比高通AR做的好一些。<br/>
而在示例demo上高通做的比easyAR要好一些，<br/>
比如识别后显示video上，高通有点击暂停，在点击播放的效果，<br/>
而且可以转入到本地播放器，而easyAR就没有这个功能。</p>
</blockquote>

<p>HiAR不推荐,不做介绍,有兴趣的自己查阅;</p>

<p>2 随着VR、AR、MR的火热，unity3D的发展也是水涨船高，<br/>
其跨平台性更是其一大亮点,(跨平台)<br/>
可以通过unity3D导出xcode工程的方法实现AR功能</p>

<p>高通AR，easyAR，HiAR，都有对应的unity3D的开发包，<br/>
导入开发包之后便可进行操作，<br/>
可以显示需要的3D或2D场景，而且也都支持云识别等。</p>

<p>注意开发时在plist文件中加入允许使用相机的属性。(权限问题,不然报错哈)</p>

<p>3 关于人脸识别解决方案，可以利用opencv的一些东西。<br/>
当然也可以用已经写好的一些第三方，比如face++，讯飞人脸识别等。</p>

<p>解决方案参考了: CSDN:baidu_33735542的博客<br/>
<a href="http://blog.csdn.net/baidu_33735542/article/details/55045539?locationNum=11&amp;fps=1">http://blog.csdn.net/baidu_33735542/article/details/55045539?locationNum=11&amp;fps=1</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[正则表达式简单说明]]></title>
    <link href="www.freefook.com/15139217121225.html"/>
    <updated>2017-12-22T13:48:32+08:00</updated>
    <id>www.freefook.com/15139217121225.html</id>
    <content type="html"><![CDATA[
<p>正则表达式，又称正规表示法，是对字符串操作的一种逻辑公式。<br/>
正则表达式可以检测给定的字符串是否符合我们定义的逻辑，<br/>
也可以从字符串中获取我们想要的特定部分。<br/>
它可以迅速地用极简单的方式达到字符串的复杂控制。</p>

<p>代码显示的部分摘自<br/>
(摘)<a href="https://github.com/shaojiankui/JKCategories">https://github.com/shaojiankui/JKCategories</a><br/>
NSString+JKNormalRegex.h</p>

<p>iOS开发的时候,Category(扩展),👆这个就是个不错的选择;<br/>
```<br/>
/**<br/>
 *  正则表达式简单说明<br/>
 *  语法：<br/>
 .       匹配除换行符以外的任意字符<br/>
 \w      匹配字母或数字或下划线或汉字<br/>
 \s      匹配任意的空白符<br/>
 \d      匹配数字<br/>
 \b      匹配单词的开始或结束<br/>
 ^       匹配字符串的开始<br/>
 \(       匹配字符串的结束<br/>
 *       重复零次或更多次<br/>
 +       重复一次或更多次<br/>
 ?       重复零次或一次<br/>
 {n}    重复n次<br/>
 {n,}   重复n次或更多次<br/>
 {n,m}  重复n到m次<br/>
 \W      匹配任意不是字母，数字，下划线，汉字的字符<br/>
 \S      匹配任意不是空白符的字符<br/>
 \D      匹配任意非数字的字符<br/>
 \B      匹配不是单词开头或结束的位置<br/>
 [^x]   匹配除了x以外的任意字符<br/>
 [^aeiou]匹配除了aeiou这几个字母以外的任意字符<br/>
 *?      重复任意次，但尽可能少重复<br/>
 +?      重复1次或更多次，但尽可能少重复<br/>
 ??      重复0次或1次，但尽可能少重复<br/>
 {n,m}?     重复n到m次，但尽可能少重复<br/>
 {n,}?  重复n次以上，但尽可能少重复<br/>
 \a      报警字符(打印它的效果是电脑嘀一声)<br/>
 \b      通常是单词分界位置，但如果在字符类里使用代表退格<br/>
 \t      制表符，Tab<br/>
 \r      回车<br/>
 \v      竖向制表符<br/>
 \f      换页符<br/>
 \n      换行符<br/>
 \e      Escape<br/>
 \0nn   ASCII代码中八进制代码为nn的字符<br/>
 \xnn   ASCII代码中十六进制代码为nn的字符<br/>
 \unnnn     Unicode代码中十六进制代码为nnnn的字符<br/>
 \cN    ASCII控制字符。比如\cC代表Ctrl+C<br/>
 \A      字符串开头(类似^，但不受处理多行选项的影响)<br/>
 \Z      字符串结尾或行尾(不受处理多行选项的影响)<br/>
 \z      字符串结尾(类似\)，但不受处理多行选项的影响)<br/>
 \G      当前搜索的开头<br/>
 \p{name}   Unicode中命名为name的字符类，例如\p{IsGreek}<br/>
 (?&gt;exp)    贪婪子表达式<br/>
 (?<x>-<y>exp)  平衡组<br/>
 (?im-nsx:exp)  在子表达式exp中改变处理选项<br/>
 (?im-nsx)       为表达式后面的部分改变处理选项<br/>
 (?(exp)yes|no)     把exp当作零宽正向先行断言，如果在这个位置能匹配，使用yes作为此组的表达式；否则使用no<br/>
 (?(exp)yes)    同上，只是使用空表达式作为no<br/>
 (?(name)yes|no) 如果命名为name的组捕获到了内容，使用yes作为表达式；否则使用no<br/>
 (?(name)yes)   同上，只是使用空表达式作为no</p>

<p>捕获<br/>
 (exp)               匹配exp,并捕获文本到自动命名的组里<br/>
 (?<name>exp)        匹配exp,并捕获文本到名称为name的组里，也可以写成(?&#39;name&#39;exp)<br/>
 (?:exp)             匹配exp,不捕获匹配的文本，也不给此分组分配组号<br/>
 零宽断言<br/>
 (?=exp)             匹配exp前面的位置<br/>
 (?&lt;=exp)            匹配exp后面的位置<br/>
 (?!exp)             匹配后面跟的不是exp的位置<br/>
 (?&lt;!exp)            匹配前面不是exp的位置<br/>
 注释<br/>
 (?#comment)         这种类型的分组不对正则表达式的处理产生任何影响，用于提供注释让人阅读</p>

<ul>
<li> 表达式：(?0\d{2}[) -]?\d{8}</li>
<li> 这个表达式可以匹配几种格式的电话号码，像(010)88886666，或022-22334455，或02912345678等。</li>
<li> 我们对它进行一些分析吧：</li>
<li> 首先是一个转义字符(,它能出现0次或1次(?),然后是一个0，后面跟着2个数字(\d{2})，然后是)或-或空格中的一个，它出现1次或不出现(?)，</li>
<li> 最后是8个数字(\d{8})
*/
```
更多正则相关查看👇这篇文章:
<a href="http://www.admin10000.com/document/5944.html">http://www.admin10000.com/document/5944.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS上传头像]]></title>
    <link href="www.freefook.com/15139215980098.html"/>
    <updated>2017-12-22T13:46:38+08:00</updated>
    <id>www.freefook.com/15139215980098.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS tableview 使用说明]]></title>
    <link href="www.freefook.com/15139214660338.html"/>
    <updated>2017-12-22T13:44:26+08:00</updated>
    <id>www.freefook.com/15139214660338.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS 数组操作方法说明]]></title>
    <link href="www.freefook.com/15139214500331.html"/>
    <updated>2017-12-22T13:44:10+08:00</updated>
    <id>www.freefook.com/15139214500331.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ios 字符串操作方法说明]]></title>
    <link href="www.freefook.com/15139214218497.html"/>
    <updated>2017-12-22T13:43:41+08:00</updated>
    <id>www.freefook.com/15139214218497.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS开发说明]]></title>
    <link href="www.freefook.com/15139213651453.html"/>
    <updated>2017-12-22T13:42:45+08:00</updated>
    <id>www.freefook.com/15139213651453.html</id>
    <content type="html"><![CDATA[
<pre><code>what？
因为基础你不会。。。

why?
因为基础你不会系列。。。

how?
因为基础你不会系列之说明。。。

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS 使用三方工具cocoaPods]]></title>
    <link href="www.freefook.com/15139117675584.html"/>
    <updated>2017-12-22T11:02:47+08:00</updated>
    <id>www.freefook.com/15139117675584.html</id>
    <content type="html"><![CDATA[
<pre><code>使用三方管理工具cocoapods
1、Ruby环境搭建
查看下当前ruby版本：打开终端输入 ruby -v

如果需要更新，进行如下操作更改Ruby镜像：

gem sources --remove https://rubygems.org/ 
gem sources -a https://gems.ruby-china.org/
gem sources -l  （用来检查使用替换镜像位置成功与否）

最后 输入  rvm install 2.2.4  更新ruby


2、下载安装CocoaPods
终端输入：sudo gem install cocoapods 

结束之后：
终端cd 到自己的项目文件下Create a Podfile

终端输入touch Podfile
       open -a Xcode Podfile


写上如下内容：
target &#39;MyApp的名’ do
  pod &#39;AFNetworking&#39;, &#39;~&gt; 3.1’
end

执行 pod install 就OK了

查询三方版本可用 pod search afnetworking  （不区分大小写）
第一次安装完pod 进行搜索需要多等一段时间，
会卡在Creating search index for spec repo &#39;master&#39;..    

CocoaPods的基本安装及使用都详细的说明了，
当需要同时导入多个第三方时候怎么办 ？
这就需要修改Podfile了，就是用vim编辑的那个保存在项目根目录中的文件，
修改完了Podfile文件，需要重新执行一次pod install命令。
</code></pre>

<h5 id="toc_0">参考如下：</h5>

<pre><code> iOS安装CocoaPods详细过程
 请查看:(http://www.jianshu.com/p/9e4e36ba8574)
 
 cocoapods报错问题You need at least git version 1.8.5 to use CocoaPods
 请查看:(http://www.jianshu.com/p/a1ab3b291f55)
 
 使用cocoapods时常见错误
 请查看:(http://www.jianshu.com/p/dfc7b93e67eb)
 
 iOS 下 Podfile 使用方法
 请查看:(http://www.cnblogs.com/Kennytian/p/6413734.html)
 
 如果出现下面问题,请尝试:cocoapods 出现 &quot;_OBJC_CLASS_$--&quot;, 
 referenced from:的问题target-&gt;build setting
  -&gt;other link flags 添加一个$(inherited) 
  
  
  
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS   创建.pch文件]]></title>
    <link href="www.freefook.com/15139119793020.html"/>
    <updated>2017-12-22T11:06:19+08:00</updated>
    <id>www.freefook.com/15139119793020.html</id>
    <content type="html"><![CDATA[
<p>command+n 滑动到最底下other 里创建pch文件。<br/>
<img src="http://upload-images.jianshu.io/upload_images/670820-06ec44085a3c68e0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="箭头所指三个选中.png"/></p>

<p><img src="http://upload-images.jianshu.io/upload_images/670820-192ddcde4df0a66f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="加粗的两项改动test是项工程名.png"/></p>

]]></content>
  </entry>
  
</feed>
